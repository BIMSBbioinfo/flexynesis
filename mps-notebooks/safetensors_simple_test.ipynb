{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b15914",
   "metadata": {},
   "source": [
    "# SafeTensors Functionality Test\n",
    "\n",
    "This notebook tests SafeTensors functionality in flexynesis-mps - a secure format for storing ML model weights without the security risks of pickle-based formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0943620f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SafeTensors functionality...\n",
      "PyTorch version: 2.8.0\n",
      "Using MPS backend\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import tempfile\n",
    "import os\n",
    "from safetensors.torch import save_file, load_file\n",
    "import flexynesis\n",
    "\n",
    "print(\"Testing SafeTensors functionality...\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check device availability\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS backend\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e8ce5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created test tensors:\n",
      "  weight_matrix: (256, 128) (torch.float32)\n",
      "  bias_vector: (128,) (torch.float32)\n",
      "  embeddings: (1000, 64) (torch.float32)\n",
      "  conv_weight: (32, 3, 3, 3) (torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Create sample tensors for testing\n",
    "test_tensors = {\n",
    "    \"weight_matrix\": torch.randn(256, 128, device=device),\n",
    "    \"bias_vector\": torch.randn(128, device=device),\n",
    "    \"embeddings\": torch.randn(1000, 64, device=device),\n",
    "    \"conv_weight\": torch.randn(32, 3, 3, 3, device=device),\n",
    "}\n",
    "\n",
    "print(\"Created test tensors:\")\n",
    "for name, tensor in test_tensors.items():\n",
    "    print(f\"  {name}: {tuple(tensor.shape)} ({tensor.dtype})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69afdbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving tensors to: /var/folders/yh/0j70fczd72jcxjytt2t_9b_m0000gn/T/safetensors_test_03wvrbpk/test_model.safetensors\n",
      "File created successfully. Size: 0.37 MB\n"
     ]
    }
   ],
   "source": [
    "# Test SafeTensors save functionality\n",
    "demo_dir = tempfile.mkdtemp(prefix=\"safetensors_test_\")\n",
    "safetensors_path = os.path.join(demo_dir, \"test_model.safetensors\")\n",
    "\n",
    "print(f\"Saving tensors to: {safetensors_path}\")\n",
    "save_file(test_tensors, safetensors_path)\n",
    "\n",
    "# Check file was created\n",
    "if os.path.exists(safetensors_path):\n",
    "    file_size = os.path.getsize(safetensors_path)\n",
    "    print(f\"File created successfully. Size: {file_size / (1024**2):.2f} MB\")\n",
    "else:\n",
    "    print(\"ERROR: File was not created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f68a20fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tensors from SafeTensors file...\n",
      "Loaded tensors:\n",
      "  bias_vector: (128,) (torch.float32)\n",
      "  conv_weight: (32, 3, 3, 3) (torch.float32)\n",
      "  embeddings: (1000, 64) (torch.float32)\n",
      "  weight_matrix: (256, 128) (torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Test SafeTensors load functionality\n",
    "print(\"Loading tensors from SafeTensors file...\")\n",
    "loaded_tensors = load_file(safetensors_path)\n",
    "\n",
    "print(\"Loaded tensors:\")\n",
    "for name, tensor in loaded_tensors.items():\n",
    "    print(f\"  {name}: {tuple(tensor.shape)} ({tensor.dtype})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d0dc8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying data integrity...\n",
      "  weight_matrix: OK\n",
      "  bias_vector: OK\n",
      "  embeddings: OK\n",
      "  weight_matrix: OK\n",
      "  bias_vector: OK\n",
      "  embeddings: OK\n",
      "  conv_weight: OK\n",
      "All tensors loaded correctly!\n",
      "  conv_weight: OK\n",
      "All tensors loaded correctly!\n"
     ]
    }
   ],
   "source": [
    "# Verify data integrity\n",
    "print(\"Verifying data integrity...\")\n",
    "all_correct = True\n",
    "\n",
    "for name in test_tensors.keys():\n",
    "    original = test_tensors[name]\n",
    "    loaded = loaded_tensors[name]\n",
    "    \n",
    "    # Move loaded tensor to same device as original for comparison\n",
    "    loaded = loaded.to(original.device)\n",
    "    \n",
    "    if torch.equal(original, loaded):\n",
    "        print(f\"  {name}: OK\")\n",
    "    else:\n",
    "        print(f\"  {name}: FAILED\")\n",
    "        all_correct = False\n",
    "\n",
    "if all_correct:\n",
    "    print(\"All tensors loaded correctly!\")\n",
    "else:\n",
    "    print(\"Some tensors failed verification!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "227f5438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SafeTensors with flexynesis model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hc/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] ================= Importing Data =================\n",
      "[INFO] Validating data folders...\n",
      "\n",
      "[INFO] ----------------- Reading Data ----------------- \n",
      "[INFO] Importing ./lgggbm_tcga_pub_processed/train/mut.csv...\n",
      "[INFO] Importing ./lgggbm_tcga_pub_processed/train/clin.csv...\n",
      "\n",
      "[INFO] ----------------- Reading Data ----------------- \n",
      "[INFO] Importing ./lgggbm_tcga_pub_processed/test/mut.csv...\n",
      "[INFO] Importing ./lgggbm_tcga_pub_processed/test/clin.csv...\n",
      "\n",
      "[INFO] ----------------- Checking for problems with the input data ----------------- \n",
      "[INFO] Data structure is valid with no errors or warnings.\n",
      "\n",
      "[INFO] ----------------- Processing Data (train) ----------------- \n",
      "\n",
      "[INFO] ----------------- Cleaning Up Data ----------------- \n",
      "\n",
      "[INFO] working on layer:  mut\n",
      "[INFO] Number of NA values:  0\n",
      "[INFO] DataFrame mut - Removed 0 features.\n",
      "[INFO] DataFrame mut - Removed 0 samples (0.00%).\n",
      "[INFO] Implementing feature selection using laplacian score for layer: mut with  11064 features  and  556  samples \n",
      "[INFO] Implementing feature selection using laplacian score for layer: mut with  11064 features  and  556  samples \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Laplacian scores:   0%|          | 0/11064 [00:00<?, ?it/s]/Users/hc/Library/Python/3.9/lib/python/site-packages/flexynesis/feature_selection.py:52: RuntimeWarning: invalid value encountered in scalar divide\n",
      "Calculating Laplacian scores:  12%|█▏        | 1321/11064 [00:00<00:00, 13206.17it/s]/Users/hc/Library/Python/3.9/lib/python/site-packages/flexynesis/feature_selection.py:52: RuntimeWarning: invalid value encountered in scalar divide\n",
      "Calculating Laplacian scores: 100%|██████████| 11064/11064 [00:00<00:00, 17689.35it/s]\n",
      "Calculating Laplacian scores: 100%|██████████| 11064/11064 [00:00<00:00, 17689.35it/s]\n",
      "Filtering redundant features: 100%|██████████| 553/553 [00:00<00:00, 22572.41it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] ----------------- Processing Data (test) ----------------- \n",
      "\n",
      "[INFO] ----------------- Cleaning Up Data ----------------- \n",
      "\n",
      "[INFO] working on layer:  mut\n",
      "[INFO] Number of NA values:  0\n",
      "[INFO] DataFrame mut - Removed 0 features.\n",
      "[INFO] DataFrame mut - Removed 0 samples (0.00%).\n",
      "\n",
      "[INFO] ----------------- Harmonizing Data Sets ----------------- \n",
      "\n",
      "[INFO] ----------------- Finished Harmonizing ----------------- \n",
      "\n",
      "[INFO] ----------------- Normalizing Data ----------------- \n",
      "\n",
      "[INFO] ----------------- Normalizing Data ----------------- \n",
      "[INFO] Training Data Stats:  {'feature_count in: mut': 553, 'sample_count': 556}\n",
      "[INFO] Test Data Stats:  {'feature_count in: mut': 553, 'sample_count': 238}\n",
      "[INFO] Merging Feature Logs...\n",
      "[INFO] Data import successful.\n",
      "Dataset loaded: torch.Size([556, 553])\n"
     ]
    }
   ],
   "source": [
    "# Test with flexynesis model\n",
    "print(\"Testing SafeTensors with flexynesis model...\")\n",
    "\n",
    "# Download test data if needed\n",
    "if not os.path.exists(\"lgggbm_tcga_pub_processed\"):\n",
    "    print(\"Downloading test dataset...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"curl\", \"-O\", \"https://bimsbstatic.mdc-berlin.de/akalin/buyar/flexynesis-benchmark-datasets/lgggbm_tcga_pub_processed.tgz\"])\n",
    "    subprocess.run([\"tar\", \"-xzvf\", \"lgggbm_tcga_pub_processed.tgz\"])\n",
    "\n",
    "# Load data using the correct import method\n",
    "data_importer = flexynesis.data.DataImporter(\n",
    "    path='./lgggbm_tcga_pub_processed/', \n",
    "    data_types=['mut'], \n",
    "    concatenate=False, \n",
    "    top_percentile=5, \n",
    "    min_features=100\n",
    ")\n",
    "train_dataset, _ = data_importer.import_data()\n",
    "print(f\"Dataset loaded: {train_dataset.dat['mut'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ad4e76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type          | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | log_vars | ParameterDict | 1      | train\n",
      "1 | encoders | ModuleList    | 162 K  | train\n",
      "2 | MLPs     | ModuleDict    | 645    | train\n",
      "---------------------------------------------------\n",
      "162 K     Trainable params\n",
      "0         Non-trainable params\n",
      "162 K     Total params\n",
      "0.652     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "\n",
      "  | Name     | Type          | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | log_vars | ParameterDict | 1      | train\n",
      "1 | encoders | ModuleList    | 162 K  | train\n",
      "2 | MLPs     | ModuleDict    | 645    | train\n",
      "---------------------------------------------------\n",
      "162 K     Trainable params\n",
      "0         Non-trainable params\n",
      "162 K     Total params\n",
      "0.652     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Users/hc/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: PossibleUserWarning: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/hc/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: PossibleUserWarning: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4adc5051ab04c348806a6ee3fe00103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hc/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/utilities/data.py:79: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/hc/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/utilities/data.py:79: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 12. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/Users/hc/Library/Python/3.9/lib/python/site-packages/lightning/pytorch/utilities/data.py:79: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 12. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed\n"
     ]
    }
   ],
   "source": [
    "# Create and train a simple model\n",
    "import lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create a complete config manually\n",
    "config = {\n",
    "    'hidden_dim_factor': 0.5,\n",
    "    'latent_dim': 32,\n",
    "    'supervisor_hidden_dim': 16,\n",
    "    'lr': 0.001,  # Use 'lr' instead of 'learning_rate'\n",
    "    'weight_decay': 0.01,\n",
    "    'dropout_rate': 0.1\n",
    "}\n",
    "\n",
    "model = flexynesis.models.DirectPred(\n",
    "    config=config,\n",
    "    dataset=train_dataset,\n",
    "    target_variables=['HISTOLOGICAL_DIAGNOSIS'],\n",
    "    device_type='mps' if torch.backends.mps.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Quick training\n",
    "trainer = pl.Trainer(max_epochs=1, enable_checkpointing=False, logger=False)\n",
    "trainer.fit(model, train_dataloader)\n",
    "print(\"Model training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5a47f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving flexynesis model with SafeTensors...\n",
      "Loading flexynesis model from SafeTensors...\n",
      "Model parameters saved: 19\n",
      "Model parameters loaded: 19\n",
      "Parameter names match: OK\n"
     ]
    }
   ],
   "source": [
    "# Test SafeTensors with trained model\n",
    "model_path = os.path.join(demo_dir, \"flexynesis_model.safetensors\")\n",
    "\n",
    "print(\"Saving flexynesis model with SafeTensors...\")\n",
    "save_file(model.state_dict(), model_path)\n",
    "\n",
    "print(\"Loading flexynesis model from SafeTensors...\")\n",
    "loaded_state = load_file(model_path)\n",
    "\n",
    "print(f\"Model parameters saved: {len(model.state_dict())}\")\n",
    "print(f\"Model parameters loaded: {len(loaded_state)}\")\n",
    "\n",
    "# Verify parameter names match\n",
    "original_keys = set(model.state_dict().keys())\n",
    "loaded_keys = set(loaded_state.keys())\n",
    "\n",
    "if original_keys == loaded_keys:\n",
    "    print(\"Parameter names match: OK\")\n",
    "else:\n",
    "    print(\"Parameter names mismatch: FAILED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcb64502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SafeTensors functionality test completed\n"
     ]
    }
   ],
   "source": [
    "# Clean up and summary\n",
    "import shutil\n",
    "shutil.rmtree(demo_dir)\n",
    "\n",
    "print(\"SafeTensors functionality test completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
