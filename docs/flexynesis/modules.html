<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>flexynesis.modules API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>flexynesis.modules</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Networks that can be reused across different architectures

import torch
from torch import nn
import torch_geometric.nn as gnn


__all__ = [&#34;Encoder&#34;, &#34;Decoder&#34;, &#34;MLP&#34;, &#34;EmbeddingNetwork&#34;, &#34;CNN&#34;, &#34;GCNN&#34;]


class Encoder(nn.Module):
    &#34;&#34;&#34;
    Encoder class for a Variational Autoencoder (VAE).
    
    The Encoder class is responsible for taking input data and generating the mean and
    log variance for the latent space representation.
    &#34;&#34;&#34;
    def __init__(self, input_dim, hidden_dims, latent_dim):
        super(Encoder, self).__init__()

        self.LeakyReLU = nn.LeakyReLU(0.2)
        
        hidden_layers = []
        
        hidden_layers.append(nn.Linear(input_dim, hidden_dims[0]))
        nn.init.xavier_uniform_(hidden_layers[-1].weight)
        hidden_layers.append(self.LeakyReLU)
        hidden_layers.append(nn.BatchNorm1d(hidden_dims[0]))

        for i in range(len(hidden_dims)-1):
            hidden_layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))
            nn.init.xavier_uniform_(hidden_layers[-1].weight)
            hidden_layers.append(self.LeakyReLU)
            hidden_layers.append(nn.BatchNorm1d(hidden_dims[i+1]))

        self.hidden_layers = nn.Sequential(*hidden_layers)
        
        self.FC_mean  = nn.Linear(hidden_dims[-1], latent_dim)
        nn.init.xavier_uniform_(self.FC_mean.weight)
        self.FC_var   = nn.Linear(hidden_dims[-1], latent_dim)
        nn.init.xavier_uniform_(self.FC_var.weight)
        
    def forward(self, x):
        &#34;&#34;&#34;
        Performs a forward pass through the Encoder network.
        
        Args:
            x (torch.Tensor): The input data tensor.
            
        Returns:
            mean (torch.Tensor): The mean of the latent space representation.
            log_var (torch.Tensor): The log variance of the latent space representation.
        &#34;&#34;&#34;
        h_       = self.hidden_layers(x)
        mean     = self.FC_mean(h_)
        log_var  = self.FC_var(h_)
        return mean, log_var
    
    
class Decoder(nn.Module):
    &#34;&#34;&#34;
    Decoder class for a Variational Autoencoder (VAE).
    
    The Decoder class is responsible for taking the latent space representation and
    generating the reconstructed output data.
    &#34;&#34;&#34;
    def __init__(self, latent_dim, hidden_dims, output_dim):
        super(Decoder, self).__init__()

        self.LeakyReLU = nn.LeakyReLU(0.2)

        hidden_layers = []

        hidden_layers.append(nn.Linear(latent_dim, hidden_dims[0]))
        nn.init.xavier_uniform_(hidden_layers[-1].weight)
        hidden_layers.append(self.LeakyReLU)
        hidden_layers.append(nn.BatchNorm1d(hidden_dims[0]))

        for i in range(len(hidden_dims) - 1):
            hidden_layers.append(nn.Linear(hidden_dims[i], hidden_dims[i + 1]))
            nn.init.xavier_uniform_(hidden_layers[-1].weight)
            hidden_layers.append(self.LeakyReLU)
            hidden_layers.append(nn.BatchNorm1d(hidden_dims[i+1]))

        self.hidden_layers = nn.Sequential(*hidden_layers)

        self.FC_output = nn.Linear(hidden_dims[-1], output_dim)
        nn.init.xavier_uniform_(self.FC_output.weight)

    def forward(self, x):
        &#34;&#34;&#34;
        Performs a forward pass through the Decoder network.
        
        Args:
            x (torch.Tensor): The input tensor representing the latent space.
            
        Returns:
            x_hat (torch.Tensor): The reconstructed output tensor.
        &#34;&#34;&#34;
        h = self.hidden_layers(x)
        x_hat = torch.sigmoid(self.FC_output(h))
        return x_hat
    

class MLP(nn.Module):
    &#34;&#34;&#34;
    A Multi-Layer Perceptron (MLP) model for regression or classification tasks.
    
    The MLP class is a simple feed-forward neural network that can be used for regression
    when `output_dim` is set to 1 or for classification when `output_dim` is greater than 1.
    &#34;&#34;&#34;
    def __init__(self, input_dim, hidden_dim, output_dim):
        &#34;&#34;&#34;
        Initializes the MLP class with the given input dimension, output dimension, and hidden layer size.
        
        Args:
            input_dim (int): The input dimension.
            hidden_dim (int, optional): The size of the hidden layer. Default is 32.
            output_dim (int): The output dimension. Set to 1 for regression tasks, and &gt; 1 for classification tasks.
        &#34;&#34;&#34;
        super(MLP, self).__init__()
        self.layer_1 = nn.Linear(input_dim, hidden_dim)
        self.layer_out = nn.Linear(hidden_dim, output_dim) if output_dim &gt; 1 else nn.Linear(hidden_dim, 1, bias=False)
        self.relu = nn.ReLU() 
        self.dropout = nn.Dropout(p=0.1)
        self.batchnorm = nn.BatchNorm1d(hidden_dim)

    def forward(self, x):
        &#34;&#34;&#34;
        Performs a forward pass through the MLP network.
        
        Args:
            x (torch.Tensor): The input data tensor.
            
        Returns:
            x (torch.Tensor): The output tensor after passing through the MLP network.
        &#34;&#34;&#34;
        x = self.layer_1(x)
        x = self.batchnorm(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.layer_out(x)
        return x


class EmbeddingNetwork(nn.Module):
    &#34;&#34;&#34;
    A simple feed-forward neural network for generating embeddings.
    
    The EmbeddingNetwork class is a straightforward feed-forward network
    that can be used to generate embeddings from input data.
    &#34;&#34;&#34;
    def __init__(self, input_size, hidden_size, output_size):
        &#34;&#34;&#34;
        Initializes the EmbeddingNetwork class with the given input size, hidden layer size, and output size.
        
        Args:
            input_size (int): The size of the input data.
            hidden_size (int): The size of the hidden layer.
            output_size (int): The size of the output layer, representing the dimensionality of the embeddings.
        &#34;&#34;&#34;
        super(EmbeddingNetwork, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        &#34;&#34;&#34;
        Performs a forward pass through the EmbeddingNetwork.
        
        Args:
            x (torch.Tensor): The input data tensor.
            
        Returns:
            x (torch.Tensor): The output tensor representing the generated embeddings.
        &#34;&#34;&#34;
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x
    

class CNN(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        &#34;&#34;&#34;
        Initialize the CNN model.

        This CNN has a single convolutional layer followed by batch normalization,
        ReLU activation, dropout, and another convolutional layer as output.

        Args:
            input_dim (int): The number of input dimensions or channels.
            hidden_dim (int): The number of hidden dimensions or channels after the first convolutional layer.
            output_dim (int): The number of output dimensions or channels after the output convolutional layer.
        &#34;&#34;&#34;
        super().__init__()

        self.layer_1 = nn.Conv1d(input_dim, hidden_dim, kernel_size=1)
        self.batchnorm = nn.BatchNorm1d(hidden_dim)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=0.1)
        self.layer_out = nn.Conv1d(hidden_dim, output_dim, kernel_size=1)

    def forward(self, x):
        &#34;&#34;&#34;
        Define the forward pass of the CNN.

        The input tensor is passed through each layer of the network in sequence.
        The input tensor is first unsqueezed to add an extra dimension, then passed through
        the first convolutional layer, batch normalization, ReLU activation, dropout,
        and finally through the output convolutional layer before being squeezed back.

        Args:
            x (Tensor): A tensor of shape (N, C), where N is the batch size and C is the number of channels.
        Returns:
            Tensor: The output tensor of shape (N, C) after passing through the CNN.
        &#34;&#34;&#34;
        # (N, C) -&gt; (N, C, L) -&gt; (N, C).
        x = x.unsqueeze(-1)
        x = self.layer_1(x)
        x = self.batchnorm(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.layer_out(x)
        x = x.squeeze(-1)
        return x


class GCNN(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        &#34;&#34;&#34;
        Initialize the GCNN model.

        This model consists of two Graph Convolutional layers, each followed by a ReLU activation.
        After the second convolutional layer, the features of nodes are aggregated.

        Args:
            input_dim (int): The number of input dimensions or features.
            hidden_dim (int): The number of hidden dimensions or features after the first graph convolutional layer.
            output_dim (int): The number of output dimensions or features after the second graph convolutional layer.
        &#34;&#34;&#34;
        self.layer_1 = gnn.GraphConv(input_dim, hidden_dim)
        self.relu_1 = nn.ReLU()
        self.layer_2 = gnn.GraphConv(hidden_dim, output_dim)
        self.relu_2 = nn.ReLU()
        self.aggregation = gnn.aggr.SumAggregation()

    def forward(self, x, edge_index, batch):
        &#34;&#34;&#34;
        Define the forward pass of the GCNN.

        The input graph data is processed through two graph convolutional layers with ReLU activation.
        Finally, the node features are aggregated.

        Args:
            x (Tensor): Node feature matrix with shape [num_nodes, input_dim].
            edge_index (LongTensor): The edge indices in COO format with shape [2, num_edges].
            batch (LongTensor): The batch vector which assigns each node to a specific example in the batch.

        Returns:
            Tensor: The output tensor after processing through the GCNN, with shape [num_nodes, output_dim].
        &#34;&#34;&#34;
        x = self.layer_1(x, edge_index)
        x = self.relu_1(x)
        x = self.layer_2(x, edge_index)
        x = self.relu_2(x)
        x = self.aggregation(x, batch)
        return x</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="flexynesis.modules.CNN"><code class="flex name class">
<span>class <span class="ident">CNN</span></span>
<span>(</span><span>input_dim, hidden_dim, output_dim)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As per the example above, an <code>__init__()</code> call to the parent class
must be made before assignment on the child.</p>
</div>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initialize the CNN model.</p>
<p>This CNN has a single convolutional layer followed by batch normalization,
ReLU activation, dropout, and another convolutional layer as output.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_dim</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of input dimensions or channels.</dd>
<dt><strong><code>hidden_dim</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of hidden dimensions or channels after the first convolutional layer.</dd>
<dt><strong><code>output_dim</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of output dimensions or channels after the output convolutional layer.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CNN(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        &#34;&#34;&#34;
        Initialize the CNN model.

        This CNN has a single convolutional layer followed by batch normalization,
        ReLU activation, dropout, and another convolutional layer as output.

        Args:
            input_dim (int): The number of input dimensions or channels.
            hidden_dim (int): The number of hidden dimensions or channels after the first convolutional layer.
            output_dim (int): The number of output dimensions or channels after the output convolutional layer.
        &#34;&#34;&#34;
        super().__init__()

        self.layer_1 = nn.Conv1d(input_dim, hidden_dim, kernel_size=1)
        self.batchnorm = nn.BatchNorm1d(hidden_dim)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=0.1)
        self.layer_out = nn.Conv1d(hidden_dim, output_dim, kernel_size=1)

    def forward(self, x):
        &#34;&#34;&#34;
        Define the forward pass of the CNN.

        The input tensor is passed through each layer of the network in sequence.
        The input tensor is first unsqueezed to add an extra dimension, then passed through
        the first convolutional layer, batch normalization, ReLU activation, dropout,
        and finally through the output convolutional layer before being squeezed back.

        Args:
            x (Tensor): A tensor of shape (N, C), where N is the batch size and C is the number of channels.
        Returns:
            Tensor: The output tensor of shape (N, C) after passing through the CNN.
        &#34;&#34;&#34;
        # (N, C) -&gt; (N, C, L) -&gt; (N, C).
        x = x.unsqueeze(-1)
        x = self.layer_1(x)
        x = self.batchnorm(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.layer_out(x)
        x = x.squeeze(-1)
        return x</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="flexynesis.modules.CNN.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Define the forward pass of the CNN.</p>
<p>The input tensor is passed through each layer of the network in sequence.
The input tensor is first unsqueezed to add an extra dimension, then passed through
the first convolutional layer, batch normalization, ReLU activation, dropout,
and finally through the output convolutional layer before being squeezed back.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>A tensor of shape (N, C), where N is the batch size and C is the number of channels.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tensor</code></dt>
<dd>The output tensor of shape (N, C) after passing through the CNN.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    &#34;&#34;&#34;
    Define the forward pass of the CNN.

    The input tensor is passed through each layer of the network in sequence.
    The input tensor is first unsqueezed to add an extra dimension, then passed through
    the first convolutional layer, batch normalization, ReLU activation, dropout,
    and finally through the output convolutional layer before being squeezed back.

    Args:
        x (Tensor): A tensor of shape (N, C), where N is the batch size and C is the number of channels.
    Returns:
        Tensor: The output tensor of shape (N, C) after passing through the CNN.
    &#34;&#34;&#34;
    # (N, C) -&gt; (N, C, L) -&gt; (N, C).
    x = x.unsqueeze(-1)
    x = self.layer_1(x)
    x = self.batchnorm(x)
    x = self.relu(x)
    x = self.dropout(x)
    x = self.layer_out(x)
    x = x.squeeze(-1)
    return x</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="flexynesis.modules.Decoder"><code class="flex name class">
<span>class <span class="ident">Decoder</span></span>
<span>(</span><span>latent_dim, hidden_dims, output_dim)</span>
</code></dt>
<dd>
<div class="desc"><p>Decoder class for a Variational Autoencoder (VAE).</p>
<p>The Decoder class is responsible for taking the latent space representation and
generating the reconstructed output data.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Decoder(nn.Module):
    &#34;&#34;&#34;
    Decoder class for a Variational Autoencoder (VAE).
    
    The Decoder class is responsible for taking the latent space representation and
    generating the reconstructed output data.
    &#34;&#34;&#34;
    def __init__(self, latent_dim, hidden_dims, output_dim):
        super(Decoder, self).__init__()

        self.LeakyReLU = nn.LeakyReLU(0.2)

        hidden_layers = []

        hidden_layers.append(nn.Linear(latent_dim, hidden_dims[0]))
        nn.init.xavier_uniform_(hidden_layers[-1].weight)
        hidden_layers.append(self.LeakyReLU)
        hidden_layers.append(nn.BatchNorm1d(hidden_dims[0]))

        for i in range(len(hidden_dims) - 1):
            hidden_layers.append(nn.Linear(hidden_dims[i], hidden_dims[i + 1]))
            nn.init.xavier_uniform_(hidden_layers[-1].weight)
            hidden_layers.append(self.LeakyReLU)
            hidden_layers.append(nn.BatchNorm1d(hidden_dims[i+1]))

        self.hidden_layers = nn.Sequential(*hidden_layers)

        self.FC_output = nn.Linear(hidden_dims[-1], output_dim)
        nn.init.xavier_uniform_(self.FC_output.weight)

    def forward(self, x):
        &#34;&#34;&#34;
        Performs a forward pass through the Decoder network.
        
        Args:
            x (torch.Tensor): The input tensor representing the latent space.
            
        Returns:
            x_hat (torch.Tensor): The reconstructed output tensor.
        &#34;&#34;&#34;
        h = self.hidden_layers(x)
        x_hat = torch.sigmoid(self.FC_output(h))
        return x_hat</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="flexynesis.modules.Decoder.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Performs a forward pass through the Decoder network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>The input tensor representing the latent space.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>x_hat (torch.Tensor): The reconstructed output tensor.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    &#34;&#34;&#34;
    Performs a forward pass through the Decoder network.
    
    Args:
        x (torch.Tensor): The input tensor representing the latent space.
        
    Returns:
        x_hat (torch.Tensor): The reconstructed output tensor.
    &#34;&#34;&#34;
    h = self.hidden_layers(x)
    x_hat = torch.sigmoid(self.FC_output(h))
    return x_hat</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="flexynesis.modules.EmbeddingNetwork"><code class="flex name class">
<span>class <span class="ident">EmbeddingNetwork</span></span>
<span>(</span><span>input_size, hidden_size, output_size)</span>
</code></dt>
<dd>
<div class="desc"><p>A simple feed-forward neural network for generating embeddings.</p>
<p>The EmbeddingNetwork class is a straightforward feed-forward network
that can be used to generate embeddings from input data.</p>
<p>Initializes the EmbeddingNetwork class with the given input size, hidden layer size, and output size.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_size</code></strong> :&ensp;<code>int</code></dt>
<dd>The size of the input data.</dd>
<dt><strong><code>hidden_size</code></strong> :&ensp;<code>int</code></dt>
<dd>The size of the hidden layer.</dd>
<dt><strong><code>output_size</code></strong> :&ensp;<code>int</code></dt>
<dd>The size of the output layer, representing the dimensionality of the embeddings.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EmbeddingNetwork(nn.Module):
    &#34;&#34;&#34;
    A simple feed-forward neural network for generating embeddings.
    
    The EmbeddingNetwork class is a straightforward feed-forward network
    that can be used to generate embeddings from input data.
    &#34;&#34;&#34;
    def __init__(self, input_size, hidden_size, output_size):
        &#34;&#34;&#34;
        Initializes the EmbeddingNetwork class with the given input size, hidden layer size, and output size.
        
        Args:
            input_size (int): The size of the input data.
            hidden_size (int): The size of the hidden layer.
            output_size (int): The size of the output layer, representing the dimensionality of the embeddings.
        &#34;&#34;&#34;
        super(EmbeddingNetwork, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        &#34;&#34;&#34;
        Performs a forward pass through the EmbeddingNetwork.
        
        Args:
            x (torch.Tensor): The input data tensor.
            
        Returns:
            x (torch.Tensor): The output tensor representing the generated embeddings.
        &#34;&#34;&#34;
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="flexynesis.modules.EmbeddingNetwork.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Performs a forward pass through the EmbeddingNetwork.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>The input data tensor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>x (torch.Tensor): The output tensor representing the generated embeddings.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    &#34;&#34;&#34;
    Performs a forward pass through the EmbeddingNetwork.
    
    Args:
        x (torch.Tensor): The input data tensor.
        
    Returns:
        x (torch.Tensor): The output tensor representing the generated embeddings.
    &#34;&#34;&#34;
    x = self.fc1(x)
    x = self.relu(x)
    x = self.fc2(x)
    return x</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="flexynesis.modules.Encoder"><code class="flex name class">
<span>class <span class="ident">Encoder</span></span>
<span>(</span><span>input_dim, hidden_dims, latent_dim)</span>
</code></dt>
<dd>
<div class="desc"><p>Encoder class for a Variational Autoencoder (VAE).</p>
<p>The Encoder class is responsible for taking input data and generating the mean and
log variance for the latent space representation.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Encoder(nn.Module):
    &#34;&#34;&#34;
    Encoder class for a Variational Autoencoder (VAE).
    
    The Encoder class is responsible for taking input data and generating the mean and
    log variance for the latent space representation.
    &#34;&#34;&#34;
    def __init__(self, input_dim, hidden_dims, latent_dim):
        super(Encoder, self).__init__()

        self.LeakyReLU = nn.LeakyReLU(0.2)
        
        hidden_layers = []
        
        hidden_layers.append(nn.Linear(input_dim, hidden_dims[0]))
        nn.init.xavier_uniform_(hidden_layers[-1].weight)
        hidden_layers.append(self.LeakyReLU)
        hidden_layers.append(nn.BatchNorm1d(hidden_dims[0]))

        for i in range(len(hidden_dims)-1):
            hidden_layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))
            nn.init.xavier_uniform_(hidden_layers[-1].weight)
            hidden_layers.append(self.LeakyReLU)
            hidden_layers.append(nn.BatchNorm1d(hidden_dims[i+1]))

        self.hidden_layers = nn.Sequential(*hidden_layers)
        
        self.FC_mean  = nn.Linear(hidden_dims[-1], latent_dim)
        nn.init.xavier_uniform_(self.FC_mean.weight)
        self.FC_var   = nn.Linear(hidden_dims[-1], latent_dim)
        nn.init.xavier_uniform_(self.FC_var.weight)
        
    def forward(self, x):
        &#34;&#34;&#34;
        Performs a forward pass through the Encoder network.
        
        Args:
            x (torch.Tensor): The input data tensor.
            
        Returns:
            mean (torch.Tensor): The mean of the latent space representation.
            log_var (torch.Tensor): The log variance of the latent space representation.
        &#34;&#34;&#34;
        h_       = self.hidden_layers(x)
        mean     = self.FC_mean(h_)
        log_var  = self.FC_var(h_)
        return mean, log_var</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="flexynesis.modules.Encoder.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Performs a forward pass through the Encoder network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>The input data tensor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>mean (torch.Tensor): The mean of the latent space representation.
log_var (torch.Tensor): The log variance of the latent space representation.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    &#34;&#34;&#34;
    Performs a forward pass through the Encoder network.
    
    Args:
        x (torch.Tensor): The input data tensor.
        
    Returns:
        mean (torch.Tensor): The mean of the latent space representation.
        log_var (torch.Tensor): The log variance of the latent space representation.
    &#34;&#34;&#34;
    h_       = self.hidden_layers(x)
    mean     = self.FC_mean(h_)
    log_var  = self.FC_var(h_)
    return mean, log_var</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="flexynesis.modules.GCNN"><code class="flex name class">
<span>class <span class="ident">GCNN</span></span>
<span>(</span><span>input_dim, hidden_dim, output_dim)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As per the example above, an <code>__init__()</code> call to the parent class
must be made before assignment on the child.</p>
</div>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GCNN(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        &#34;&#34;&#34;
        Initialize the GCNN model.

        This model consists of two Graph Convolutional layers, each followed by a ReLU activation.
        After the second convolutional layer, the features of nodes are aggregated.

        Args:
            input_dim (int): The number of input dimensions or features.
            hidden_dim (int): The number of hidden dimensions or features after the first graph convolutional layer.
            output_dim (int): The number of output dimensions or features after the second graph convolutional layer.
        &#34;&#34;&#34;
        self.layer_1 = gnn.GraphConv(input_dim, hidden_dim)
        self.relu_1 = nn.ReLU()
        self.layer_2 = gnn.GraphConv(hidden_dim, output_dim)
        self.relu_2 = nn.ReLU()
        self.aggregation = gnn.aggr.SumAggregation()

    def forward(self, x, edge_index, batch):
        &#34;&#34;&#34;
        Define the forward pass of the GCNN.

        The input graph data is processed through two graph convolutional layers with ReLU activation.
        Finally, the node features are aggregated.

        Args:
            x (Tensor): Node feature matrix with shape [num_nodes, input_dim].
            edge_index (LongTensor): The edge indices in COO format with shape [2, num_edges].
            batch (LongTensor): The batch vector which assigns each node to a specific example in the batch.

        Returns:
            Tensor: The output tensor after processing through the GCNN, with shape [num_nodes, output_dim].
        &#34;&#34;&#34;
        x = self.layer_1(x, edge_index)
        x = self.relu_1(x)
        x = self.layer_2(x, edge_index)
        x = self.relu_2(x)
        x = self.aggregation(x, batch)
        return x</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="flexynesis.modules.GCNN.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x, edge_index, batch) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Define the forward pass of the GCNN.</p>
<p>The input graph data is processed through two graph convolutional layers with ReLU activation.
Finally, the node features are aggregated.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>Node feature matrix with shape [num_nodes, input_dim].</dd>
<dt><strong><code>edge_index</code></strong> :&ensp;<code>LongTensor</code></dt>
<dd>The edge indices in COO format with shape [2, num_edges].</dd>
<dt><strong><code>batch</code></strong> :&ensp;<code>LongTensor</code></dt>
<dd>The batch vector which assigns each node to a specific example in the batch.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tensor</code></dt>
<dd>The output tensor after processing through the GCNN, with shape [num_nodes, output_dim].</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x, edge_index, batch):
    &#34;&#34;&#34;
    Define the forward pass of the GCNN.

    The input graph data is processed through two graph convolutional layers with ReLU activation.
    Finally, the node features are aggregated.

    Args:
        x (Tensor): Node feature matrix with shape [num_nodes, input_dim].
        edge_index (LongTensor): The edge indices in COO format with shape [2, num_edges].
        batch (LongTensor): The batch vector which assigns each node to a specific example in the batch.

    Returns:
        Tensor: The output tensor after processing through the GCNN, with shape [num_nodes, output_dim].
    &#34;&#34;&#34;
    x = self.layer_1(x, edge_index)
    x = self.relu_1(x)
    x = self.layer_2(x, edge_index)
    x = self.relu_2(x)
    x = self.aggregation(x, batch)
    return x</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="flexynesis.modules.MLP"><code class="flex name class">
<span>class <span class="ident">MLP</span></span>
<span>(</span><span>input_dim, hidden_dim, output_dim)</span>
</code></dt>
<dd>
<div class="desc"><p>A Multi-Layer Perceptron (MLP) model for regression or classification tasks.</p>
<p>The MLP class is a simple feed-forward neural network that can be used for regression
when <code>output_dim</code> is set to 1 or for classification when <code>output_dim</code> is greater than 1.</p>
<p>Initializes the MLP class with the given input dimension, output dimension, and hidden layer size.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_dim</code></strong> :&ensp;<code>int</code></dt>
<dd>The input dimension.</dd>
<dt><strong><code>hidden_dim</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The size of the hidden layer. Default is 32.</dd>
<dt><strong><code>output_dim</code></strong> :&ensp;<code>int</code></dt>
<dd>The output dimension. Set to 1 for regression tasks, and &gt; 1 for classification tasks.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MLP(nn.Module):
    &#34;&#34;&#34;
    A Multi-Layer Perceptron (MLP) model for regression or classification tasks.
    
    The MLP class is a simple feed-forward neural network that can be used for regression
    when `output_dim` is set to 1 or for classification when `output_dim` is greater than 1.
    &#34;&#34;&#34;
    def __init__(self, input_dim, hidden_dim, output_dim):
        &#34;&#34;&#34;
        Initializes the MLP class with the given input dimension, output dimension, and hidden layer size.
        
        Args:
            input_dim (int): The input dimension.
            hidden_dim (int, optional): The size of the hidden layer. Default is 32.
            output_dim (int): The output dimension. Set to 1 for regression tasks, and &gt; 1 for classification tasks.
        &#34;&#34;&#34;
        super(MLP, self).__init__()
        self.layer_1 = nn.Linear(input_dim, hidden_dim)
        self.layer_out = nn.Linear(hidden_dim, output_dim) if output_dim &gt; 1 else nn.Linear(hidden_dim, 1, bias=False)
        self.relu = nn.ReLU() 
        self.dropout = nn.Dropout(p=0.1)
        self.batchnorm = nn.BatchNorm1d(hidden_dim)

    def forward(self, x):
        &#34;&#34;&#34;
        Performs a forward pass through the MLP network.
        
        Args:
            x (torch.Tensor): The input data tensor.
            
        Returns:
            x (torch.Tensor): The output tensor after passing through the MLP network.
        &#34;&#34;&#34;
        x = self.layer_1(x)
        x = self.batchnorm(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.layer_out(x)
        return x</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="flexynesis.modules.MLP.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Performs a forward pass through the MLP network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>The input data tensor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>x (torch.Tensor): The output tensor after passing through the MLP network.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    &#34;&#34;&#34;
    Performs a forward pass through the MLP network.
    
    Args:
        x (torch.Tensor): The input data tensor.
        
    Returns:
        x (torch.Tensor): The output tensor after passing through the MLP network.
    &#34;&#34;&#34;
    x = self.layer_1(x)
    x = self.batchnorm(x)
    x = self.relu(x)
    x = self.dropout(x)
    x = self.layer_out(x)
    return x</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="flexynesis" href="index.html">flexynesis</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="flexynesis.modules.CNN" href="#flexynesis.modules.CNN">CNN</a></code></h4>
<ul class="">
<li><code><a title="flexynesis.modules.CNN.forward" href="#flexynesis.modules.CNN.forward">forward</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="flexynesis.modules.Decoder" href="#flexynesis.modules.Decoder">Decoder</a></code></h4>
<ul class="">
<li><code><a title="flexynesis.modules.Decoder.forward" href="#flexynesis.modules.Decoder.forward">forward</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="flexynesis.modules.EmbeddingNetwork" href="#flexynesis.modules.EmbeddingNetwork">EmbeddingNetwork</a></code></h4>
<ul class="">
<li><code><a title="flexynesis.modules.EmbeddingNetwork.forward" href="#flexynesis.modules.EmbeddingNetwork.forward">forward</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="flexynesis.modules.Encoder" href="#flexynesis.modules.Encoder">Encoder</a></code></h4>
<ul class="">
<li><code><a title="flexynesis.modules.Encoder.forward" href="#flexynesis.modules.Encoder.forward">forward</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="flexynesis.modules.GCNN" href="#flexynesis.modules.GCNN">GCNN</a></code></h4>
<ul class="">
<li><code><a title="flexynesis.modules.GCNN.forward" href="#flexynesis.modules.GCNN.forward">forward</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="flexynesis.modules.MLP" href="#flexynesis.modules.MLP">MLP</a></code></h4>
<ul class="">
<li><code><a title="flexynesis.modules.MLP.forward" href="#flexynesis.modules.MLP.forward">forward</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>