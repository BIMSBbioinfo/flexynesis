<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>flexynesis.models.direct_pred_gcnn API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>flexynesis.models.direct_pred_gcnn</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import torch

from torch import nn
from torch.nn import functional as F
from torch.utils.data import random_split
import pytorch_lightning as pl

import numpy as np
import pandas as pd

from torch_geometric.loader import DataLoader
from captum.attr import IntegratedGradients

from ..modules import GCNN, MLP


class DirectPredGCNN(pl.LightningModule):
    def __init__(self, config, dataset, target_variables, batch_variables=None, val_size=0.2, use_loss_weighting=True):
        super().__init__()
        self.config = config
        self.dataset = dataset
        self.target_variables = target_variables
        self.batch_variables = batch_variables
        self.variables = target_variables + batch_variables if batch_variables else target_variables
        self.val_size = val_size
        self.dat_train, self.dat_val = self.prepare_data()
        self.feature_importances = {}
        self.use_loss_weighting = use_loss_weighting

        if self.use_loss_weighting:
            # Initialize log variance parameters for uncertainty weighting
            self.log_vars = nn.ParameterDict()
            for var in self.variables:
                self.log_vars[var] = nn.Parameter(torch.zeros(1))

        # Init modality encoders
        layers = list(self.dataset.dat.keys())
        # NOTE: For now we use matrices, so number of node input features is 1.
        input_dims = [1 for i in range(len(layers))]

        self.encoders = nn.ModuleList([
            GCNN(
                input_dim=input_dims[i],
                hidden_dim=int(self.config[&#34;hidden_dim&#34;]),  # int because of pyg
                output_dim=self.config[&#34;latent_dim&#34;],
            )
            for i in range(len(layers))
        ])

        # Init output layers
        self.MLPs = nn.ModuleDict()
        for var in self.target_variables:
            if self.dataset.variable_types[var] == &#34;numerical&#34;:
                num_class = 1
            else:
                num_class = len(np.unique(self.dataset.ann[var]))
            self.MLPs[var] = MLP(
                input_dim=self.config[&#34;latent_dim&#34;] * len(layers),
                hidden_dim=self.config[&#34;hidden_dim&#34;],
                output_dim=num_class,
            )

    def forward(self, x_list):
        embeddings_list = []
        # Process each input matrix with its corresponding Encoder
        for i, x in enumerate(x_list):
            embeddings_list.append(self.encoders[i](x.x, x.edge_index, x.batch))
        embeddings_concat = torch.cat(embeddings_list, dim=1)

        outputs = {}
        for var, mlp in self.MLPs.items():
            outputs[var] = mlp(embeddings_concat)
        return outputs  

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.config[&#34;lr&#34;])
        return optimizer

    def compute_loss(self, var, y, y_hat):
        if self.dataset.variable_types[var] == &#34;numerical&#34;:
            # Ignore instances with missing labels for numerical variables
            valid_indices = ~torch.isnan(y)
            if valid_indices.sum() &gt; 0:  # only calculate loss if there are valid targets
                y_hat = y_hat[valid_indices]
                y = y[valid_indices]
                loss = F.mse_loss(torch.flatten(y_hat), y.float())
            else:
                loss = torch.tensor(0.0, device=y_hat.device, requires_grad=True) # if no valid labels, set loss to 0
        else:
            # Ignore instances with missing labels for categorical variables
            # Assuming that missing values were encoded as -1
            valid_indices = (y != -1) &amp; (~torch.isnan(y))
            if valid_indices.sum() &gt; 0:  # only calculate loss if there are valid targets
                y_hat = y_hat[valid_indices]
                y = y[valid_indices]
                loss = F.cross_entropy(y_hat, y.long())
            else:
                loss = torch.tensor(0.0, device=y_hat.device, requires_grad=True)
        return loss

    def compute_total_loss(self, losses):
        if self.use_loss_weighting and len(losses) &gt; 1:
            # Compute weighted loss for each loss 
            # Weighted loss = precision * loss + log-variance
            total_loss = sum(torch.exp(-self.log_vars[name]) * loss + self.log_vars[name] for name, loss in losses.items())
        else:
            # Compute unweighted total loss
            total_loss = sum(losses.values())
        return total_loss

    def training_step(self, train_batch, batch_idx):
        dat, y_dict = train_batch
        layers = dat.keys()
        x_list = [dat[x] for x in layers]

        outputs = self.forward(x_list)

        losses = {}
        for var in self.variables:
            y_hat = outputs[var]
            y = y_dict[var]
            loss = self.compute_loss(var, y, y_hat)
            losses[var] = loss

        total_loss = self.compute_total_loss(losses)
        losses[&#34;train_loss&#34;] = total_loss
        self.log_dict(losses, on_step=False, on_epoch=True, prog_bar=True, batch_size=int(x_list[0].batch_size))
        return total_loss

    def validation_step(self, val_batch, batch_idx):
        dat, y_dict = val_batch
        layers = dat.keys()
        x_list = [dat[x] for x in layers]

        outputs = self.forward(x_list)

        losses = {}
        for var in self.variables:
            y_hat = outputs[var]
            y = y_dict[var]
            loss = self.compute_loss(var, y, y_hat)
            losses[var] = loss

        total_loss = sum(losses.values())
        losses[&#34;val_loss&#34;] = total_loss
        self.log_dict(losses, on_step=False, on_epoch=True, prog_bar=True, batch_size=int(x_list[0].batch_size))
        return total_loss

    def prepare_data(self):
        lt = int(len(self.dataset) * (1 - self.val_size))
        lv = len(self.dataset) - lt
        dat_train, dat_val = random_split(self.dataset, [lt, lv], generator=torch.Generator().manual_seed(42))
        return dat_train, dat_val

    def train_dataloader(self):
        return DataLoader(self.dat_train, batch_size=int(self.config[&#34;batch_size&#34;]), num_workers=0, pin_memory=True, shuffle=True, drop_last=True)

    def val_dataloader(self):
        return DataLoader(self.dat_val, batch_size=int(self.config[&#34;batch_size&#34;]), num_workers=0, pin_memory=True, shuffle=False)

    def predict(self, dataset):
        self.eval()
        layers = dataset.dat.keys()
        x_list = [dataset.dat[x] for x in layers]
        outputs = self.forward(x_list)

        predictions = {}
        for var in self.target_variables:
            y_pred = outputs[var].detach().numpy()
            if self.dataset.variable_types[var] == &#34;categorical&#34;:
                predictions[var] = np.argmax(y_pred, axis=1)
            else:
                predictions[var] = y_pred
        return predictions

    def transform(self, dataset):
        self.eval()
        embeddings_list = []
        # Process each input matrix with its corresponding Encoder
        for i, x in enumerate(dataset.dat.values()):
            embeddings_list.append(self.encoders[i](x))
        embeddings_concat = torch.cat(embeddings_list, dim=1)

        # Converting tensor to numpy array and then to DataFrame
        embeddings_df = pd.DataFrame(
            embeddings_concat.detach().numpy(),
            index=dataset.samples,
            columns=[f&#34;E{dim}&#34; for dim in range(embeddings_concat.shape[1])],
        )
        return embeddings_df

    def forward_target(self, *args):
        &#34;&#34;&#34;Adaptor forward function for captum integrated gradients.
        &#34;&#34;&#34;
        raise NotImplementedError

    def compute_feature_importance(self, target_var, steps=5):
        raise NotImplementedError</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="flexynesis.models.direct_pred_gcnn.DirectPredGCNN"><code class="flex name class">
<span>class <span class="ident">DirectPredGCNN</span></span>
<span>(</span><span>config, dataset, target_variables, batch_variables=None, val_size=0.2, use_loss_weighting=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Hooks to be used in LightningModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DirectPredGCNN(pl.LightningModule):
    def __init__(self, config, dataset, target_variables, batch_variables=None, val_size=0.2, use_loss_weighting=True):
        super().__init__()
        self.config = config
        self.dataset = dataset
        self.target_variables = target_variables
        self.batch_variables = batch_variables
        self.variables = target_variables + batch_variables if batch_variables else target_variables
        self.val_size = val_size
        self.dat_train, self.dat_val = self.prepare_data()
        self.feature_importances = {}
        self.use_loss_weighting = use_loss_weighting

        if self.use_loss_weighting:
            # Initialize log variance parameters for uncertainty weighting
            self.log_vars = nn.ParameterDict()
            for var in self.variables:
                self.log_vars[var] = nn.Parameter(torch.zeros(1))

        # Init modality encoders
        layers = list(self.dataset.dat.keys())
        # NOTE: For now we use matrices, so number of node input features is 1.
        input_dims = [1 for i in range(len(layers))]

        self.encoders = nn.ModuleList([
            GCNN(
                input_dim=input_dims[i],
                hidden_dim=int(self.config[&#34;hidden_dim&#34;]),  # int because of pyg
                output_dim=self.config[&#34;latent_dim&#34;],
            )
            for i in range(len(layers))
        ])

        # Init output layers
        self.MLPs = nn.ModuleDict()
        for var in self.target_variables:
            if self.dataset.variable_types[var] == &#34;numerical&#34;:
                num_class = 1
            else:
                num_class = len(np.unique(self.dataset.ann[var]))
            self.MLPs[var] = MLP(
                input_dim=self.config[&#34;latent_dim&#34;] * len(layers),
                hidden_dim=self.config[&#34;hidden_dim&#34;],
                output_dim=num_class,
            )

    def forward(self, x_list):
        embeddings_list = []
        # Process each input matrix with its corresponding Encoder
        for i, x in enumerate(x_list):
            embeddings_list.append(self.encoders[i](x.x, x.edge_index, x.batch))
        embeddings_concat = torch.cat(embeddings_list, dim=1)

        outputs = {}
        for var, mlp in self.MLPs.items():
            outputs[var] = mlp(embeddings_concat)
        return outputs  

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.config[&#34;lr&#34;])
        return optimizer

    def compute_loss(self, var, y, y_hat):
        if self.dataset.variable_types[var] == &#34;numerical&#34;:
            # Ignore instances with missing labels for numerical variables
            valid_indices = ~torch.isnan(y)
            if valid_indices.sum() &gt; 0:  # only calculate loss if there are valid targets
                y_hat = y_hat[valid_indices]
                y = y[valid_indices]
                loss = F.mse_loss(torch.flatten(y_hat), y.float())
            else:
                loss = torch.tensor(0.0, device=y_hat.device, requires_grad=True) # if no valid labels, set loss to 0
        else:
            # Ignore instances with missing labels for categorical variables
            # Assuming that missing values were encoded as -1
            valid_indices = (y != -1) &amp; (~torch.isnan(y))
            if valid_indices.sum() &gt; 0:  # only calculate loss if there are valid targets
                y_hat = y_hat[valid_indices]
                y = y[valid_indices]
                loss = F.cross_entropy(y_hat, y.long())
            else:
                loss = torch.tensor(0.0, device=y_hat.device, requires_grad=True)
        return loss

    def compute_total_loss(self, losses):
        if self.use_loss_weighting and len(losses) &gt; 1:
            # Compute weighted loss for each loss 
            # Weighted loss = precision * loss + log-variance
            total_loss = sum(torch.exp(-self.log_vars[name]) * loss + self.log_vars[name] for name, loss in losses.items())
        else:
            # Compute unweighted total loss
            total_loss = sum(losses.values())
        return total_loss

    def training_step(self, train_batch, batch_idx):
        dat, y_dict = train_batch
        layers = dat.keys()
        x_list = [dat[x] for x in layers]

        outputs = self.forward(x_list)

        losses = {}
        for var in self.variables:
            y_hat = outputs[var]
            y = y_dict[var]
            loss = self.compute_loss(var, y, y_hat)
            losses[var] = loss

        total_loss = self.compute_total_loss(losses)
        losses[&#34;train_loss&#34;] = total_loss
        self.log_dict(losses, on_step=False, on_epoch=True, prog_bar=True, batch_size=int(x_list[0].batch_size))
        return total_loss

    def validation_step(self, val_batch, batch_idx):
        dat, y_dict = val_batch
        layers = dat.keys()
        x_list = [dat[x] for x in layers]

        outputs = self.forward(x_list)

        losses = {}
        for var in self.variables:
            y_hat = outputs[var]
            y = y_dict[var]
            loss = self.compute_loss(var, y, y_hat)
            losses[var] = loss

        total_loss = sum(losses.values())
        losses[&#34;val_loss&#34;] = total_loss
        self.log_dict(losses, on_step=False, on_epoch=True, prog_bar=True, batch_size=int(x_list[0].batch_size))
        return total_loss

    def prepare_data(self):
        lt = int(len(self.dataset) * (1 - self.val_size))
        lv = len(self.dataset) - lt
        dat_train, dat_val = random_split(self.dataset, [lt, lv], generator=torch.Generator().manual_seed(42))
        return dat_train, dat_val

    def train_dataloader(self):
        return DataLoader(self.dat_train, batch_size=int(self.config[&#34;batch_size&#34;]), num_workers=0, pin_memory=True, shuffle=True, drop_last=True)

    def val_dataloader(self):
        return DataLoader(self.dat_val, batch_size=int(self.config[&#34;batch_size&#34;]), num_workers=0, pin_memory=True, shuffle=False)

    def predict(self, dataset):
        self.eval()
        layers = dataset.dat.keys()
        x_list = [dataset.dat[x] for x in layers]
        outputs = self.forward(x_list)

        predictions = {}
        for var in self.target_variables:
            y_pred = outputs[var].detach().numpy()
            if self.dataset.variable_types[var] == &#34;categorical&#34;:
                predictions[var] = np.argmax(y_pred, axis=1)
            else:
                predictions[var] = y_pred
        return predictions

    def transform(self, dataset):
        self.eval()
        embeddings_list = []
        # Process each input matrix with its corresponding Encoder
        for i, x in enumerate(dataset.dat.values()):
            embeddings_list.append(self.encoders[i](x))
        embeddings_concat = torch.cat(embeddings_list, dim=1)

        # Converting tensor to numpy array and then to DataFrame
        embeddings_df = pd.DataFrame(
            embeddings_concat.detach().numpy(),
            index=dataset.samples,
            columns=[f&#34;E{dim}&#34; for dim in range(embeddings_concat.shape[1])],
        )
        return embeddings_df

    def forward_target(self, *args):
        &#34;&#34;&#34;Adaptor forward function for captum integrated gradients.
        &#34;&#34;&#34;
        raise NotImplementedError

    def compute_feature_importance(self, target_var, steps=5):
        raise NotImplementedError</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>pytorch_lightning.core.module.LightningModule</li>
<li>lightning_fabric.utilities.device_dtype_mixin._DeviceDtypeModuleMixin</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
<li>pytorch_lightning.core.hooks.ModelHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.compute_feature_importance"><code class="name flex">
<span>def <span class="ident">compute_feature_importance</span></span>(<span>self, target_var, steps=5)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_feature_importance(self, target_var, steps=5):
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.compute_loss"><code class="name flex">
<span>def <span class="ident">compute_loss</span></span>(<span>self, var, y, y_hat)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_loss(self, var, y, y_hat):
    if self.dataset.variable_types[var] == &#34;numerical&#34;:
        # Ignore instances with missing labels for numerical variables
        valid_indices = ~torch.isnan(y)
        if valid_indices.sum() &gt; 0:  # only calculate loss if there are valid targets
            y_hat = y_hat[valid_indices]
            y = y[valid_indices]
            loss = F.mse_loss(torch.flatten(y_hat), y.float())
        else:
            loss = torch.tensor(0.0, device=y_hat.device, requires_grad=True) # if no valid labels, set loss to 0
    else:
        # Ignore instances with missing labels for categorical variables
        # Assuming that missing values were encoded as -1
        valid_indices = (y != -1) &amp; (~torch.isnan(y))
        if valid_indices.sum() &gt; 0:  # only calculate loss if there are valid targets
            y_hat = y_hat[valid_indices]
            y = y[valid_indices]
            loss = F.cross_entropy(y_hat, y.long())
        else:
            loss = torch.tensor(0.0, device=y_hat.device, requires_grad=True)
    return loss</code></pre>
</details>
</dd>
<dt id="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.compute_total_loss"><code class="name flex">
<span>def <span class="ident">compute_total_loss</span></span>(<span>self, losses)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_total_loss(self, losses):
    if self.use_loss_weighting and len(losses) &gt; 1:
        # Compute weighted loss for each loss 
        # Weighted loss = precision * loss + log-variance
        total_loss = sum(torch.exp(-self.log_vars[name]) * loss + self.log_vars[name] for name, loss in losses.items())
    else:
        # Compute unweighted total loss
        total_loss = sum(losses.values())
    return total_loss</code></pre>
</details>
</dd>
<dt id="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.configure_optimizers"><code class="name flex">
<span>def <span class="ident">configure_optimizers</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you'd need one.
But in the case of GANs or similar you might have multiple. Optimization with multiple optimizers only works in
the manual optimization mode.</p>
<h2 id="return">Return</h2>
<p>Any of these 6 options.</p>
<ul>
<li><strong>Single optimizer</strong>.</li>
<li><strong>List or Tuple</strong> of optimizers.</li>
<li><strong>Two lists</strong> - The first list has multiple optimizers, and the second has multiple LR schedulers
(or multiple <code>lr_scheduler_config</code>).</li>
<li><strong>Dictionary</strong>, with an <code>"optimizer"</code> key, and (optionally) a <code>"lr_scheduler"</code>
key whose value is a single LR scheduler or <code>lr_scheduler_config</code>.</li>
<li><strong>None</strong> - Fit will run without any optimizer.</li>
</ul>
<p>The <code>lr_scheduler_config</code> is a dictionary which contains the scheduler and its associated configuration.
The default configuration is shown below.</p>
<p>.. code-block:: python</p>
<pre><code>lr_scheduler_config = {
    # REQUIRED: The scheduler instance
    "scheduler": lr_scheduler,
    # The unit of the scheduler's step size, could also be 'step'.
    # 'epoch' updates the scheduler on epoch end whereas 'step'
    # updates it after a optimizer update.
    "interval": "epoch",
    # How many epochs/steps should pass between calls to
    # &lt;code&gt;scheduler.step()&lt;/code&gt;. 1 corresponds to updating the learning
    # rate after every epoch/step.
    "frequency": 1,
    # Metric to to monitor for schedulers like &lt;code&gt;ReduceLROnPlateau&lt;/code&gt;
    "monitor": "val_loss",
    # If set to &lt;code&gt;True&lt;/code&gt;, will enforce that the value specified 'monitor'
    # is available when the scheduler is updated, thus stopping
    # training if not found. If set to &lt;code&gt;False&lt;/code&gt;, it will only produce a warning
    "strict": True,
    # If using the &lt;code&gt;LearningRateMonitor&lt;/code&gt; callback to monitor the
    # learning rate progress, this keyword can be used to specify
    # a custom logged name
    "name": None,
}
</code></pre>
<p>When there are schedulers in which the <code>.step()</code> method is conditioned on a value, such as the
:class:<code>torch.optim.lr_scheduler.ReduceLROnPlateau</code> scheduler, Lightning requires that the
<code>lr_scheduler_config</code> contains the keyword <code>"monitor"</code> set to the metric name that the scheduler
should be conditioned on.</p>
<div class="admonition testcode">
<p class="admonition-title">Testcode</p>
<h1 id="the-reducelronplateau-scheduler-requires-a-monitor">The ReduceLROnPlateau scheduler requires a monitor</h1>
<p>def configure_optimizers(self):
optimizer = Adam(&hellip;)
return {
"optimizer": optimizer,
"lr_scheduler": {
"scheduler": ReduceLROnPlateau(optimizer, &hellip;),
"monitor": "metric_to_track",
"frequency": "indicates how often the metric is updated"
# If "monitor" references validation metrics, then "frequency" should be set to a
# multiple of "trainer.check_val_every_n_epoch".
},
}</p>
<h1 id="in-the-case-of-two-optimizers-only-one-using-the-reducelronplateau-scheduler">In the case of two optimizers, only one using the ReduceLROnPlateau scheduler</h1>
<p>def configure_optimizers(self):
optimizer1 = Adam(&hellip;)
optimizer2 = SGD(&hellip;)
scheduler1 = ReduceLROnPlateau(optimizer1, &hellip;)
scheduler2 = LambdaLR(optimizer2, &hellip;)
return (
{
"optimizer": optimizer1,
"lr_scheduler": {
"scheduler": scheduler1,
"monitor": "metric_to_track",
},
},
{"optimizer": optimizer2, "lr_scheduler": scheduler2},
)</p>
</div>
<p>Metrics can be made available to monitor by simply logging it using
<code>self.log('metric_to_track', metric_val)</code> in your :class:<code>~pytorch_lightning.core.LightningModule</code>.</p>
<h2 id="note">Note</h2>
<p>Some things to know:</p>
<ul>
<li>Lightning calls <code>.backward()</code> and <code>.step()</code> automatically in case of automatic optimization.</li>
<li>If a learning rate scheduler is specified in <code>configure_optimizers()</code> with key
<code>"interval"</code> (default "epoch") in the scheduler configuration, Lightning will call
the scheduler's <code>.step()</code> method automatically in case of automatic optimization.</li>
<li>If you use 16-bit precision (<code>precision=16</code>), Lightning will automatically handle the optimizer.</li>
<li>If you use :class:<code>torch.optim.LBFGS</code>, Lightning handles the closure function automatically for you.</li>
<li>If you use multiple optimizers, you will have to switch to 'manual optimization' mode and step them
yourself.</li>
<li>If you need to control how often the optimizer steps, override the :meth:<code>optimizer_step</code> hook.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def configure_optimizers(self):
    optimizer = torch.optim.Adam(self.parameters(), lr=self.config[&#34;lr&#34;])
    return optimizer</code></pre>
</details>
</dd>
<dt id="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x_list) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Same as :meth:<code>torch.nn.Module.forward</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>*args</code></strong></dt>
<dd>Whatever you decide to pass into the forward method.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Keyword arguments are also possible.</dd>
</dl>
<h2 id="return">Return</h2>
<p>Your model's output</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x_list):
    embeddings_list = []
    # Process each input matrix with its corresponding Encoder
    for i, x in enumerate(x_list):
        embeddings_list.append(self.encoders[i](x.x, x.edge_index, x.batch))
    embeddings_concat = torch.cat(embeddings_list, dim=1)

    outputs = {}
    for var, mlp in self.MLPs.items():
        outputs[var] = mlp(embeddings_concat)
    return outputs  </code></pre>
</details>
</dd>
<dt id="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.forward_target"><code class="name flex">
<span>def <span class="ident">forward_target</span></span>(<span>self, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Adaptor forward function for captum integrated gradients.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward_target(self, *args):
    &#34;&#34;&#34;Adaptor forward function for captum integrated gradients.
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, dataset)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, dataset):
    self.eval()
    layers = dataset.dat.keys()
    x_list = [dataset.dat[x] for x in layers]
    outputs = self.forward(x_list)

    predictions = {}
    for var in self.target_variables:
        y_pred = outputs[var].detach().numpy()
        if self.dataset.variable_types[var] == &#34;categorical&#34;:
            predictions[var] = np.argmax(y_pred, axis=1)
        else:
            predictions[var] = y_pred
    return predictions</code></pre>
</details>
</dd>
<dt id="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.prepare_data"><code class="name flex">
<span>def <span class="ident">prepare_data</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Use this to download and prepare data. Downloading and saving data with multiple processes (distributed
settings) will result in corrupted data. Lightning ensures this method is called only within a single process,
so you can safely add your downloading logic within.</p>
<div class="admonition warning">
<p class="admonition-title">Warning:&ensp;DO NOT set state to the model (use <code>setup</code> instead)</p>
<p>since this is NOT called on every device</p>
</div>
<p>Example::</p>
<pre><code>def prepare_data(self):
    # good
    download_data()
    tokenize()
    etc()

    # bad
    self.split = data_split
    self.some_state = some_other_state()
</code></pre>
<p>In a distributed environment, <code>prepare_data</code> can be called in two ways
(using :ref:<code>prepare_data_per_node&lt;common/lightning_module:prepare_data_per_node&gt;</code>)</p>
<ol>
<li>Once per node. This is the default and is only called on LOCAL_RANK=0.</li>
<li>Once in total. Only called on GLOBAL_RANK=0.</li>
</ol>
<p>Example::</p>
<pre><code># DEFAULT
# called once per node on LOCAL_RANK=0 of that node
class LitDataModule(LightningDataModule):
    def __init__(self):
        super().__init__()
        self.prepare_data_per_node = True


# call on GLOBAL_RANK=0 (great for shared file systems)
class LitDataModule(LightningDataModule):
    def __init__(self):
        super().__init__()
        self.prepare_data_per_node = False
</code></pre>
<p>This is called before requesting the dataloaders:</p>
<p>.. code-block:: python</p>
<pre><code>model.prepare_data()
initialize_distributed()
model.setup(stage)
model.train_dataloader()
model.val_dataloader()
model.test_dataloader()
model.predict_dataloader()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare_data(self):
    lt = int(len(self.dataset) * (1 - self.val_size))
    lv = len(self.dataset) - lt
    dat_train, dat_val = random_split(self.dataset, [lt, lv], generator=torch.Generator().manual_seed(42))
    return dat_train, dat_val</code></pre>
</details>
</dd>
<dt id="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.train_dataloader"><code class="name flex">
<span>def <span class="ident">train_dataloader</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>An iterable or collection of iterables specifying training samples.</p>
<p>For more information about multiple dataloaders, see this :ref:<code>section &lt;multiple-dataloaders&gt;</code>.</p>
<p>The dataloader you return will not be reloaded unless you set
:paramref:<code>~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs</code> to
a positive integer.</p>
<p>For data processing use the following pattern:</p>
<pre><code>- download in :meth:&lt;code&gt;prepare\_data&lt;/code&gt;
- process and split in :meth:&lt;code&gt;setup&lt;/code&gt;
</code></pre>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning:&ensp;do not assign state in prepare_data</p>
</div>
<ul>
<li>:meth:<code>~pytorch_lightning.trainer.trainer.Trainer.fit</code></li>
<li>:meth:<code>prepare_data</code></li>
<li>:meth:<code>setup</code></li>
</ul>
<h2 id="note">Note</h2>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_dataloader(self):
    return DataLoader(self.dat_train, batch_size=int(self.config[&#34;batch_size&#34;]), num_workers=0, pin_memory=True, shuffle=True, drop_last=True)</code></pre>
</details>
</dd>
<dt id="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.training_step"><code class="name flex">
<span>def <span class="ident">training_step</span></span>(<span>self, train_batch, batch_idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Here you compute and return the training loss and some additional metrics for e.g. the progress bar or
logger.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>batch</code></strong></dt>
<dd>The output of your data iterable, normally a :class:<code>~torch.utils.data.DataLoader</code>.</dd>
<dt><strong><code>batch_idx</code></strong></dt>
<dd>The index of this batch.</dd>
<dt><strong><code>dataloader_idx</code></strong></dt>
<dd>The index of the dataloader that produced this batch.
(only if multiple dataloaders used)</dd>
</dl>
<h2 id="return">Return</h2>
<ul>
<li>:class:<code>~torch.Tensor</code> - The loss tensor</li>
<li><code>dict</code> - A dictionary. Can include any keys, but must include the key <code>'loss'</code>.</li>
<li><code>None</code> - Skip to the next batch. This is only supported for automatic optimization.
This is not supported for multi-GPU, TPU, IPU, or DeepSpeed.</li>
</ul>
<p>In this step you'd normally do the forward pass and calculate the loss for a batch.
You can also do fancier things like multiple forward passes or something model specific.</p>
<p>Example::</p>
<pre><code>def training_step(self, batch, batch_idx):
    x, y, z = batch
    out = self.encoder(x)
    loss = self.loss(out, x)
    return loss
</code></pre>
<p>To use multiple optimizers, you can switch to 'manual optimization' and control their stepping:</p>
<p>.. code-block:: python</p>
<pre><code>def __init__(self):
    super().__init__()
    self.automatic_optimization = False


# Multiple optimizers (e.g.: GANs)
def training_step(self, batch, batch_idx):
    opt1, opt2 = self.optimizers()

    # do training_step with encoder
    ...
    opt1.step()
    # do training_step with decoder
    ...
    opt2.step()
</code></pre>
<h2 id="note">Note</h2>
<p>When <code>accumulate_grad_batches</code> &gt; 1, the loss returned here will be automatically
normalized by <code>accumulate_grad_batches</code> internally.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def training_step(self, train_batch, batch_idx):
    dat, y_dict = train_batch
    layers = dat.keys()
    x_list = [dat[x] for x in layers]

    outputs = self.forward(x_list)

    losses = {}
    for var in self.variables:
        y_hat = outputs[var]
        y = y_dict[var]
        loss = self.compute_loss(var, y, y_hat)
        losses[var] = loss

    total_loss = self.compute_total_loss(losses)
    losses[&#34;train_loss&#34;] = total_loss
    self.log_dict(losses, on_step=False, on_epoch=True, prog_bar=True, batch_size=int(x_list[0].batch_size))
    return total_loss</code></pre>
</details>
</dd>
<dt id="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.transform"><code class="name flex">
<span>def <span class="ident">transform</span></span>(<span>self, dataset)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, dataset):
    self.eval()
    embeddings_list = []
    # Process each input matrix with its corresponding Encoder
    for i, x in enumerate(dataset.dat.values()):
        embeddings_list.append(self.encoders[i](x))
    embeddings_concat = torch.cat(embeddings_list, dim=1)

    # Converting tensor to numpy array and then to DataFrame
    embeddings_df = pd.DataFrame(
        embeddings_concat.detach().numpy(),
        index=dataset.samples,
        columns=[f&#34;E{dim}&#34; for dim in range(embeddings_concat.shape[1])],
    )
    return embeddings_df</code></pre>
</details>
</dd>
<dt id="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.val_dataloader"><code class="name flex">
<span>def <span class="ident">val_dataloader</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>An iterable or collection of iterables specifying validation samples.</p>
<p>For more information about multiple dataloaders, see this :ref:<code>section &lt;multiple-dataloaders&gt;</code>.</p>
<p>The dataloader you return will not be reloaded unless you set
:paramref:<code>~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs</code> to
a positive integer.</p>
<p>It's recommended that all data downloads and preparation happen in :meth:<code>prepare_data</code>.</p>
<ul>
<li>:meth:<code>~pytorch_lightning.trainer.trainer.Trainer.fit</code></li>
<li>:meth:<code>~pytorch_lightning.trainer.trainer.Trainer.validate</code></li>
<li>:meth:<code>prepare_data</code></li>
<li>:meth:<code>setup</code></li>
</ul>
<h2 id="note">Note</h2>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware
There is no need to set it yourself.</p>
<h2 id="note_1">Note</h2>
<p>If you don't need a validation dataset and a :meth:<code>validation_step</code>, you don't need to
implement this method.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def val_dataloader(self):
    return DataLoader(self.dat_val, batch_size=int(self.config[&#34;batch_size&#34;]), num_workers=0, pin_memory=True, shuffle=False)</code></pre>
</details>
</dd>
<dt id="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.validation_step"><code class="name flex">
<span>def <span class="ident">validation_step</span></span>(<span>self, val_batch, batch_idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Operates on a single batch of data from the validation set. In this step you'd might generate examples or
calculate anything of interest like accuracy.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>batch</code></strong></dt>
<dd>The output of your data iterable, normally a :class:<code>~torch.utils.data.DataLoader</code>.</dd>
<dt><strong><code>batch_idx</code></strong></dt>
<dd>The index of this batch.</dd>
<dt><strong><code>dataloader_idx</code></strong></dt>
<dd>The index of the dataloader that produced this batch.
(only if multiple dataloaders used)</dd>
</dl>
<h2 id="return">Return</h2>
<ul>
<li>:class:<code>~torch.Tensor</code> - The loss tensor</li>
<li><code>dict</code> - A dictionary. Can include any keys, but must include the key <code>'loss'</code>.</li>
<li><code>None</code> - Skip to the next batch.</li>
</ul>
<p>.. code-block:: python</p>
<pre><code># if you have one val dataloader:
def validation_step(self, batch, batch_idx):
    ...


# if you have multiple val dataloaders:
def validation_step(self, batch, batch_idx, dataloader_idx=0):
    ...
</code></pre>
<p>Examples::</p>
<pre><code># CASE 1: A single validation dataset
def validation_step(self, batch, batch_idx):
    x, y = batch

    # implement your own
    out = self(x)
    loss = self.loss(out, y)

    # log 6 example images
    # or generated text... or whatever
    sample_imgs = x[:6]
    grid = torchvision.utils.make_grid(sample_imgs)
    self.logger.experiment.add_image('example_images', grid, 0)

    # calculate acc
    labels_hat = torch.argmax(out, dim=1)
    val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)

    # log the outputs!
    self.log_dict({'val_loss': loss, 'val_acc': val_acc})
</code></pre>
<p>If you pass in multiple val dataloaders, :meth:<code>validation_step</code> will have an additional argument. We recommend
setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>
<p>.. code-block:: python</p>
<pre><code># CASE 2: multiple validation dataloaders
def validation_step(self, batch, batch_idx, dataloader_idx=0):
    # dataloader_idx tells you which dataset this is.
    ...
</code></pre>
<h2 id="note">Note</h2>
<p>If you don't need to validate you don't need to implement this method.</p>
<h2 id="note_1">Note</h2>
<p>When the :meth:<code>validation_step</code> is called, the model has been put in eval mode
and PyTorch gradients have been disabled. At the end of validation,
the model goes back to training mode and gradients are enabled.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def validation_step(self, val_batch, batch_idx):
    dat, y_dict = val_batch
    layers = dat.keys()
    x_list = [dat[x] for x in layers]

    outputs = self.forward(x_list)

    losses = {}
    for var in self.variables:
        y_hat = outputs[var]
        y = y_dict[var]
        loss = self.compute_loss(var, y, y_hat)
        losses[var] = loss

    total_loss = sum(losses.values())
    losses[&#34;val_loss&#34;] = total_loss
    self.log_dict(losses, on_step=False, on_epoch=True, prog_bar=True, batch_size=int(x_list[0].batch_size))
    return total_loss</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="flexynesis.models" href="index.html">flexynesis.models</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="flexynesis.models.direct_pred_gcnn.DirectPredGCNN" href="#flexynesis.models.direct_pred_gcnn.DirectPredGCNN">DirectPredGCNN</a></code></h4>
<ul class="">
<li><code><a title="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.compute_feature_importance" href="#flexynesis.models.direct_pred_gcnn.DirectPredGCNN.compute_feature_importance">compute_feature_importance</a></code></li>
<li><code><a title="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.compute_loss" href="#flexynesis.models.direct_pred_gcnn.DirectPredGCNN.compute_loss">compute_loss</a></code></li>
<li><code><a title="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.compute_total_loss" href="#flexynesis.models.direct_pred_gcnn.DirectPredGCNN.compute_total_loss">compute_total_loss</a></code></li>
<li><code><a title="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.configure_optimizers" href="#flexynesis.models.direct_pred_gcnn.DirectPredGCNN.configure_optimizers">configure_optimizers</a></code></li>
<li><code><a title="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.forward" href="#flexynesis.models.direct_pred_gcnn.DirectPredGCNN.forward">forward</a></code></li>
<li><code><a title="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.forward_target" href="#flexynesis.models.direct_pred_gcnn.DirectPredGCNN.forward_target">forward_target</a></code></li>
<li><code><a title="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.predict" href="#flexynesis.models.direct_pred_gcnn.DirectPredGCNN.predict">predict</a></code></li>
<li><code><a title="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.prepare_data" href="#flexynesis.models.direct_pred_gcnn.DirectPredGCNN.prepare_data">prepare_data</a></code></li>
<li><code><a title="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.train_dataloader" href="#flexynesis.models.direct_pred_gcnn.DirectPredGCNN.train_dataloader">train_dataloader</a></code></li>
<li><code><a title="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.training_step" href="#flexynesis.models.direct_pred_gcnn.DirectPredGCNN.training_step">training_step</a></code></li>
<li><code><a title="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.transform" href="#flexynesis.models.direct_pred_gcnn.DirectPredGCNN.transform">transform</a></code></li>
<li><code><a title="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.val_dataloader" href="#flexynesis.models.direct_pred_gcnn.DirectPredGCNN.val_dataloader">val_dataloader</a></code></li>
<li><code><a title="flexynesis.models.direct_pred_gcnn.DirectPredGCNN.validation_step" href="#flexynesis.models.direct_pred_gcnn.DirectPredGCNN.validation_step">validation_step</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>